{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"data/alice.txt\"\n",
    "raw_text = open(fname).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 163817\n"
     ]
    }
   ],
   "source": [
    "text_len = len(raw_text)\n",
    "print('Text length:', text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 61\n"
     ]
    }
   ],
   "source": [
    "charset = sorted(list(set(raw_text)))\n",
    "char_to_int = {c:i for (i,c) in enumerate(charset)}\n",
    "int_to_char = {i:c for (i,c) in enumerate(charset)}\n",
    "n_vocab = len(charset)\n",
    "print('Number of characters:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 163717\n"
     ]
    }
   ],
   "source": [
    "seqs, next_chars = [], []\n",
    "for i in range(text_len - max_seq_len):\n",
    "    seqs.append(raw_text[i:i+max_seq_len])\n",
    "    next_chars.append(raw_text[i+max_seq_len])\n",
    "n_seqs = len(seqs)\n",
    "print('Number of sequences:', n_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros([n_seqs, max_seq_len, n_vocab], dtype=np.bool)\n",
    "y = np.zeros([n_seqs, n_vocab], dtype=np.bool)\n",
    "\n",
    "for i,seq in enumerate(seqs):\n",
    "    for j,c in enumerate(seq):\n",
    "        X[i,j,char_to_int[c]] = 1\n",
    "    y[i,char_to_int[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(max_seq_len,n_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose=0,\n",
    "                                  save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "callbacks_list = [model_checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to retrain\n",
    "\n",
    "# nb_epoch = 20\n",
    "# batch_size = 128\n",
    "# model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading model from weight\n",
    "\n",
    "weight_fname = 'alice_weights_iter20_loss1.10.hdf5'\n",
    "model.load_weights(weight_fname)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Starting sentence:---\n",
      "\n",
      "\n",
      "‘oh, as to the whiting,’ said the mock turtle, ‘they--you’ve seen them,\n",
      "of course?’\n",
      "\n",
      "‘yes,’ said al\n",
      "\n",
      "---Generated text:---\n",
      "\n",
      "ice, and a long all to the same weak in it, ‘i cool found here, sthermy, and that’s she was a count--in a dry again!’ he didnnot leaged, and alice was not a little come sorpimar\n",
      "tones and was going and fingea pully\n",
      "wearnou in and off, and de, when it was a duchess to see the use of the offore that, and she heard\n",
      "at the shill oner bifte of the hadds.\n",
      "\n",
      "‘out fer ith of rath hep a sound--everything i’ve bedid,’ said the hatter in the\n",
      "good.\n",
      "\n",
      "‘i don’t say a meaning\n",
      "a doess in that in\n",
      "the simp of the court!’\n",
      "\n",
      "\n",
      "the hatter with a samply: ‘beciatafile,’ he thought, ‘i’ll get out it pursand it to do\n",
      "one off a time: it’s no one of the table\n",
      "word election or use and amary was which was going and much of it was till as she could go,\n",
      "in the\n",
      "other play with\n",
      "an a procosside. there were see it to shoulder at the queen off the sime, and against one of the hangard at one of the english, and each teerul to alice because they houred and buch and glad to deer the silence.\n",
      "\n",
      "‘i adventy down,’ the mock turtle. "
     ]
    }
   ],
   "source": [
    "# Generate random start\n",
    "\n",
    "num_iter = 1000\n",
    "temperature = 0.8\n",
    "start = np.random.randint(0,text_len-max_seq_len-1,size=1)\n",
    "sentence = raw_text[start:start+max_seq_len]\n",
    "print('\\n---Starting sentence:---\\n')\n",
    "print(sentence)\n",
    "\n",
    "\n",
    "print('\\n---Generated text:---\\n')\n",
    "for i in range(num_iter):\n",
    "    x = np.zeros((1, max_seq_len, n_vocab))\n",
    "    for j,c in enumerate(sentence):\n",
    "        x[0,j,char_to_int[c]] = 1\n",
    "    prediction = model.predict(x)[0]\n",
    "    sample_idx = int(sample(prediction,temperature))\n",
    "    next_char = int_to_char[sample_idx]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    print(next_char,end='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
