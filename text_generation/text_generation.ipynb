{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"data/alice.txt\"\n",
    "raw_text = open(fname).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 163817\n"
     ]
    }
   ],
   "source": [
    "text_len = len(raw_text)\n",
    "print('Text length:', text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 61\n"
     ]
    }
   ],
   "source": [
    "charset = sorted(list(set(raw_text)))\n",
    "char_to_int = {c:i for (i,c) in enumerate(charset)}\n",
    "int_to_char = {i:c for (i,c) in enumerate(charset)}\n",
    "n_vocab = len(charset)\n",
    "print('Number of characters:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 163717\n"
     ]
    }
   ],
   "source": [
    "seqs, next_chars = [], []\n",
    "for i in range(text_len - max_seq_len):\n",
    "    seqs.append(raw_text[i:i+max_seq_len])\n",
    "    next_chars.append(raw_text[i+max_seq_len])\n",
    "n_seqs = len(seqs)\n",
    "print('Number of sequences:', n_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros([n_seqs, max_seq_len, n_vocab], dtype=np.bool)\n",
    "y = np.zeros([n_seqs, n_vocab], dtype=np.bool)\n",
    "\n",
    "for i,seq in enumerate(seqs):\n",
    "    for j,c in enumerate(seq):\n",
    "        X[i,j,char_to_int[c]] = 1\n",
    "    y[i,char_to_int[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(max_seq_len,n_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose=0,\n",
    "                                  save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "callbacks_list = [model_checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to retrain\n",
    "\n",
    "# nb_epoch = 20\n",
    "# batch_size = 128\n",
    "# model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading model from weight\n",
    "\n",
    "weight_fname = 'weights.19-1.10.hdf5'\n",
    "model.load_weights(weight_fname)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " didn’t write it, and they\n",
      "can’t prove i did: there’s no name signed at the end.’\n",
      "\n",
      "‘if you didn’t silented that she was and them,’ said the caterpillar.\n",
      "\n",
      "‘it was a treak butter, the caterpillar walle!’ said the hatter.\n",
      "\n",
      "‘i dinn’t a deepland it,’ said the queen, and she had sort\n",
      "of the hatter were all trouse on the little king and head to go, and well be a great dirach a a child: and\n",
      "passions all\n",
      "the united stated. in a bogenelf that she said to change the cook to the sound of the going, and the footman in the sound of her head to alice, the queen was getting a brish of the queen, and then was to was so much first, and said to herself and got in a bouth, and alice was a very much in a treacl of the table, but she was quite pleased to himsely in it, and the way of course, the party was the little golden the sumple. i don’t the marke cat would this again, and she was a little is the right to be a little baty on the sound of been and sighing as she could\n",
      "crowd of the other of the suchated\n",
      "of the look of the party of the way the hatter.\n",
      "\n",
      "the hatter said ‘no round\n",
      "it as it just as well, i "
     ]
    }
   ],
   "source": [
    "# Generate random start\n",
    "\n",
    "num_iter = 1000\n",
    "temperature = 0.5\n",
    "start = np.random.randint(0,text_len-max_seq_len-1,size=1)\n",
    "sentence = raw_text[start:start+max_seq_len]\n",
    "print(sentence,end='')\n",
    "\n",
    "for i in range(num_iter):\n",
    "    x = np.zeros((1, max_seq_len, n_vocab))\n",
    "    for j,c in enumerate(sentence):\n",
    "        x[0,j,char_to_int[c]] = 1\n",
    "    prediction = model.predict(x)[0]\n",
    "    sample_idx = int(sample(prediction,temperature))\n",
    "    next_char = int_to_char[sample_idx]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    print(next_char,end='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
